One Ring Dist is a utility dedicated for transferring data to and from the cluster, and a much faster replacement to `dist-cp` and `s3-distp-cp`.

### Introduction

The S3 object storage is not too well suited for Spark due to data non-locality and its architectural peculiarities (as it isn't a true filesystem but object storage). It is generally recommended to always copy the source data from S3 to HDFS on the cluster before Spark invocation, and, vice versa, to copy the result back from HDFS to S3 after it has been computed.

EMR provides an utility named `s3-dist-cp`, and there is plain vanilla `dist-cp` but their usage is cumbersome because the user must always know the exact paths beforehand, and the invocation syntax is complex. Another drawback that these utilities are implemented with very dated MapReduce approach, have low parallelism, and utilize cluster resources inefficiently. Also, there is no facility for handling Parquet files.

One Ring provides an alternative implementation named One Ring Dist that focuses around your Task config, so you can still use Variables for source paths and generate result paths dynamically while not bothering yourself with `dist-cp` command line. It is written on top of Spark, has much better parallelism, and it can convert Parquet files to CSV as required by One Ring CLI.

### Calling One Ring Dist

The syntax is similar to CLI:
```bash
java -jar ./Dist/target/one-ring-dist.jar -c /path/to/tasks.ini -S /path/to/dist_interface.file -d DIRECTION -x spark.meta
```

`-c`, `-x`, `-v`/`-V` switches have the same meaning for Dist as to CLI.

`-d` specifies the direction of the copying process:
* `from` to copy the source data from S3 to HDFS,
* `to` to copy the result back.

`-S` specifies the path to interface file with a list of HDFS paths of Task outputs generated by the CLI.

### Configuration

Dist has its own layer in `tasks.ini`, prefixed with `dist.`, with a small set of keys.

`dist.direction` sets which copy operations are implied to be performed. In addition to `-d` switch `from` and `to` there are:
 * `both` to indicate the copy in both directions is required,
 * `nop` (default) to suppress the copying.

Boolean `dist.move` directs to remove files after copying. By default it is set to `true`.

`dist.dir.to` and `dist.dir.from` specify which on-cluster (or local) paths are to be used to store files gathered from HDFS and for the results respectively, with the defaults of `hdfs:///input` and `hdfs:///output`. Subdirectories named after DataStreams will be automatically created for their files under these paths.

`dist.store` provides another way to set `-S` value (but command line switch always has higher priority, if both were set).

But for the data, it uses same `task`, `ds.input.` and `ds.output.` layers as CLI, and therefore honors all partitioning and column-related parameters. So, it does repartition and rearrangement of columns of source files on the fly while copying to and from the cluster. Moreover, it converts Parquet files and unpacks compressed files to plain old CSV. Because of that, you can freely mix Parquet, `.csv.gz` and `.csv.bz2` files for the same input data set as long as they have compatible schemas.

### Usage

When CLI encounters `dist.direction` directive in the config, it transparently replaces all its S3 input and output paths with HDFS paths according to the provided direction.

This is useful for multi-Process tasks.ini. If the outputs from the first Task are stored in HDFS, it allows next Tasks to consume them without a round-trip to S3 while still providing the paths pointing to S3:
```properties
spark.task1.dist.direction=to
spark.task2.dist.direction=nop
spark.task3.dist.direction=from
```
...and if same Task is executed solo, it should just use bi-directional copy:
```properties
spark.task1.dist.direction=both
```
...without further changes to path Variables and other configuration parameters.

For any DataStream that goes to `dist.dir.from` the CLI adds a line to `dist.store` / `-S` file with the resulting local path. That allows Dist to gather them for the `from` direction.

Actually you should never invoke Dist manually, it is a job of automation scripts to call it before and after the execution of CLI.
